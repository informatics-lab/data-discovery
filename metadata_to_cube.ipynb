{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets load a cube from metadata alone. This is a proof of concept showing the potential of storing metadata seperately from cubes.\n",
    "\n",
    "The metadata here is json dumps of the original netcdf file headers. It could just as easily have come from a database query etc. There is a benefit here that the metadata is already on my local disk rather than requiring a database query.\n",
    "\n",
    "It is ~500 faster to load cubes in this way (almost entirely down to network traffic). 210s -> 0.4s.\n",
    "\n",
    "I don't bother adding attributes to the cube, because it messes up merging. It would be trivial to add all the attributes, and with a little thought we could add only the attributes that don't break the merge.\n",
    "\n",
    "I also haven't added cell methods, which are very important. I think it's easy though.\n",
    "\n",
    "There is a bug in this code. The notebook to generate this metdata only captures variable points where len(variable.shape) == 1. E.g. lat and lon points, but not data points. This is not correct - height is a scalar variable with len(variable.shape) == 0, and time_bnds is a variable with len(variable.shape) == 2, and both should have been captured. Easy to fix but again important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import iris\n",
    "import dask.array as da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n"
     ]
    }
   ],
   "source": [
    "records= json.load(open('./example_nc_headers.json', 'r'))\n",
    "print(len(records))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bnds': {'name': 'bnds', 'size': 2, 'unlimited': False},\n",
       " 'lat': {'name': 'lat', 'size': 324, 'unlimited': False},\n",
       " 'lon': {'name': 'lon', 'size': 432, 'unlimited': False},\n",
       " 'time': {'name': 'time', 'size': 48, 'unlimited': True}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records[0]['dimensions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'axis': 'Z', 'chartostring': 'True', 'datatype': 'float64', 'dimensions': '()', 'dtype': 'float64', 'long_name': 'height', 'mask': 'True', 'name': 'height', 'ndim': '0', 'positive': 'up', 'scale': 'True', 'shape': '()', 'size': '1.0', 'standard_name': 'height', 'units': 'm'}\n"
     ]
    }
   ],
   "source": [
    "print(records[0]['variables']['height'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix bug in how the metadata was extracted\n",
    "# (code only got data for variables with len(shape) == 1, height has len(shape) 0)\n",
    "for record in records:\n",
    "    record['variables']['height'].update({'points': [1.5]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variable_to_dimcoord(variable):\n",
    "    attrs = ['points', 'standard_name', 'long_name', 'var_name', 'units']\n",
    "    points = variable['points']\n",
    "    standard_name = variable['standard_name']\n",
    "    long_name = variable['long_name']\n",
    "    var_name = None #variable['var_name']\n",
    "    units = variable['units']\n",
    "    return iris.coords.DimCoord(\n",
    "        points=points,\n",
    "        standard_name=standard_name,\n",
    "        long_name=long_name,\n",
    "        var_name=var_name, units=units)\n",
    "    #bounds=None, attributes=None, coord_system=None, circular=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = variable_to_dimcoord(records[0]['variables']['lat'])\n",
    "lon = variable_to_dimcoord(records[0]['variables']['lon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variable_to_cube(record, variable_name='tas'):\n",
    "    # bunch of evals in here because the export from netcdf just stringified everything\n",
    "    # obviously not a good way to re-import.\n",
    "    var = record['variables'][variable_name] # dictionary\n",
    "    dims = eval(var['dimensions']) # yeah yeah. it's a tuple of dim names\n",
    "    dim_coords = [variable_to_dimcoord(record['variables'][dim]) for dim in dims]\n",
    "    \n",
    "    # data object\n",
    "    shape = eval(var['shape'])\n",
    "    dtype = var['dtype']\n",
    "    path = record['filename']\n",
    "    data = iris.fileformats.netcdf.NetCDFDataProxy(\n",
    "        shape=shape,\n",
    "        dtype=dtype,\n",
    "        path=path,\n",
    "        variable_name=variable_name,\n",
    "        fill_value=None)\n",
    "    \n",
    "    \n",
    "    cube = iris.cube.Cube(\n",
    "        data=da.from_array(data, chunks=shape),\n",
    "        standard_name=var['standard_name'],\n",
    "        long_name=var['long_name'],\n",
    "        var_name=None,\n",
    "        units = var['units'],\n",
    "        dim_coords_and_dims=[(coord, i) for i, coord in enumerate(dim_coords)]\n",
    "        )\n",
    "    \n",
    "    return cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 363 ms, sys: 7.51 ms, total: 371 ms\n",
      "Wall time: 372 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "c = iris.cube.CubeList([variable_to_cube(record) for record in records]).concatenate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: air_temperature / (K)               (time: 648; latitude: 324; longitude: 432)\n",
      "1: air_temperature / (K)               (time: 648; latitude: 324; longitude: 432)\n",
      "2: air_temperature / (K)               (time: 648; latitude: 324; longitude: 432)\n",
      "3: air_temperature / (K)               (time: 648; latitude: 324; longitude: 432)\n",
      "4: air_temperature / (K)               (time: 648; latitude: 324; longitude: 432)\n",
      "5: air_temperature / (K)               (time: 648; latitude: 324; longitude: 432)\n",
      "6: air_temperature / (K)               (time: 648; latitude: 324; longitude: 432)\n",
      "7: air_temperature / (K)               (time: 648; latitude: 324; longitude: 432)\n",
      "8: air_temperature / (K)               (time: 648; latitude: 324; longitude: 432)\n",
      "9: air_temperature / (K)               (time: 648; latitude: 324; longitude: 432)\n",
      "10: air_temperature / (K)               (time: 648; latitude: 324; longitude: 432)\n",
      "11: air_temperature / (K)               (time: 648; latitude: 324; longitude: 432)\n",
      "12: air_temperature / (K)               (time: 648; latitude: 324; longitude: 432)\n",
      "13: air_temperature / (K)               (time: 648; latitude: 324; longitude: 432)\n",
      "14: air_temperature / (K)               (time: 648; latitude: 324; longitude: 432)\n"
     ]
    }
   ],
   "source": [
    "print(c) # realization is only in the nc file as an attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.269790e+09'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"%e\"% (648*324*432*14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "DuplicateDataError",
     "evalue": "failed to merge into a single cube.\n  Duplicate 'air_temperature' cube, with scalar coordinates ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDuplicateDataError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-8245b82cb998>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/data_vis/lib/python3.6/site-packages/iris/cube.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(self, unique)\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto_cubes_by_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_none_sort\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mproto_cube\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproto_cubes_by_name\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m                 \u001b[0mmerged_cubes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto_cube\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmerged_cubes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/data_vis/lib/python3.6/site-packages/iris/_merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(self, unique)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0;31m# Check for unique data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0munique\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mgroup_depth\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_report_duplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnd_indexes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_by_nd_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0;31m# Generate group-depth merged cubes from the source-cubes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/data_vis/lib/python3.6/site-packages/iris/_merge.py\u001b[0m in \u001b[0;36m_report_duplicate\u001b[0;34m(self, nd_indexes, group_by_nd_index)\u001b[0m\n\u001b[1;32m   1147\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Duplicate %r cube, with scalar coordinates %s'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscalars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0miris\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDuplicateDataError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munique\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDuplicateDataError\u001b[0m: failed to merge into a single cube.\n  Duplicate 'air_temperature' cube, with scalar coordinates "
     ]
    }
   ],
   "source": [
    "c.merge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    c2 = iris.load([record['filename'] for record in records]).concatenate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(c2) # iris won't concat as attributes differ (e.g. each nc file has a uuid :/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
